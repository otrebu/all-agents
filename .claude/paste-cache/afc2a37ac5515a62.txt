# A Unified Framework for Autonomous Software Development

### 0. Vocabulary and Core Concepts

To ensure operational consistency, we are establishing a unified vocabulary that aligns concepts from various sources with our project's specific terminology. This glossary is the canonical reference for all project stakeholders and system components, serving as a foundational reference for the framework detailed in the subsequent sections.

| Framework Term | Source Concept(s) & Definition |
|---|---|
| **Roadmap** | The high-level strategic vision document outlining the project's overarching goals and major objectives. It is the precursor to all other planning artifacts and lives at `docs/planning/roadmap-<n>/`. |
| **User Story** | **Source Concepts:** Jobs to be Done (JTBD). **Definition:** Captures the "what, for whom, and why" of a feature. It defines a user-centric outcome and its associated acceptance criteria, serving as the primary source of truth for the agent's work. Located in `docs/planning/roadmap-<n>/stories/*`. Each Story has a unique identifier (e.g., `STORY-001`) referenced by its child Tasks. |
| **Task** | **Source Concepts:** Derived from comparing User Stories to the codebase. **Definition:** A technical, actionable unit of work that implements part of a User Story. Tasks bridge the user-centric "why" with the technical "how". Located in `docs/planning/roadmap-<n>/tasks/*`. Each Task references its parent Story and has a unique identifier (e.g., `TASK-001`) referenced by its child Subtasks. A single Task typically decomposes into multiple Subtasks. |
| **Subtask** | **Definition:** The smallest atomic unit of work, representing a single implementable step within a Task. Multiple Subtasks combine to complete a Task. Each Subtask references its parent Task (and transitively, its grandparent Story). Stored in `subtasks.json` with fields for `id`, `taskRef`, `storyRef`, `description`, and `status`. |
| **Ralph Iteration** | A single, discrete execution cycle within Building Mode. Each iteration is memoryless and self-contained, selecting and completing one Subtask before terminating cleanly. |
| **Planning Mode** | **Source Concepts:** Ralph Playbook planning loop. **Definition:** An operational mode spanning from Roadmap interpretation through subtasks.json creation. It performs gap analysis between User Stories (specs) and current code, generating prioritized Tasks and decomposing them into Subtasks. It does not implement code. |
| **Building Mode** | **Source Concepts:** Ralph Playbook building loop. **Definition:** The primary autonomous implementation mode. The agent selects a Subtask from subtasks.json, implements it, validates its work against backpressure, and commits the result. It operates in discrete, memoryless Ralph Iterations. |
| **Calibration Mode** | The governance layer running alongside the main workflow. Encompasses Intention Drift monitoring, Technical Drift correction, and Agent Self-Improvement loops. Operates periodically to ensure long-term alignment and system optimization. |
| **Intention Drift** | The divergence of the implemented functionality from the original intent defined in the User Story or Roadmap. This represents a failure to meet the user's "why." |
| **Technical Drift** | The deviation of the implemented code from established technical documentation, architectural patterns, or engineering best practices. This represents a failure to adhere to the project's "how." |

#### 0.1. The Traceability Chain

All work artifacts form a strict hierarchy with bidirectional references:

```
Roadmap
  └── Story (STORY-001)
        ├── Task (TASK-001) → references STORY-001
        │     ├── Subtask (SUB-001) → references TASK-001, STORY-001
        │     ├── Subtask (SUB-002) → references TASK-001, STORY-001
        │     └── Subtask (SUB-003) → references TASK-001, STORY-001
        └── Task (TASK-002) → references STORY-001
              ├── Subtask (SUB-004) → references TASK-002, STORY-001
              └── Subtask (SUB-005) → references TASK-002, STORY-001
```

This traceability ensures:
- Every Subtask can be traced back to the user need it serves
- Completion status rolls up (all Subtasks done → Task done → Story done)
- Intention Drift detection can compare implementation against original Story intent
- Impact analysis: changing a Story surfaces all affected Tasks and Subtasks

### 1. The Core Philosophy: Engineering the Loop

The foundation of our framework is a paradigm shift in the nature of software development. We are moving from a human-centric process of manual implementation to a system where humans engineer and oversee autonomous agents. As described by Geoffrey Huntley, the developer's new role is analogous to a "locomotive engineer," whose primary job is to keep the autonomous agent "on the track." This is achieved not by writing code directly, but by engineering effective backpressure, defining clear specifications, and curating the operational environment.

We govern this system with the principle of **"humans on the loop, not in it."** Unlike traditional methodologies designed for human collaboration (e.g., agile ceremonies), this framework re-evaluates every practice from first principles to optimize for an AI-native workflow. Practices that introduce complexity or ambiguity for a machine, such as certain serialization formats, must be reconsidered in favor of what is most efficient and deterministic for the agent.

The central technical challenge this philosophy addresses is **"context rot."** As Geoffrey Huntley asserts, long-running agentic processes suffer when context is passed between sessions, because context compaction is "the devil"—a "lossy function" that can cause the agent to lose what he calls "the pin," its frame of reference. Our framework avoids this pitfall by treating each Ralph Iteration as a fresh, memoryless session that starts with a deterministically constructed context. This practice of "deterministically malicking the array" is not an optimization but a foundational rejection of a flawed alternative, ensuring the agent always operates within its "smart zone" with a clean and complete understanding of its objective. This philosophy is implemented through a structured, multi-phase lifecycle that separates strategic planning from autonomous execution, with ongoing calibration for quality assurance.

### 2. The Development Lifecycle

The framework divides the development process into three distinct operational modes: a human-guided **Planning Mode** to define the work, a machine-driven **Building Mode** for autonomous implementation, and a periodic **Calibration Mode** for governance and self-improvement. This separation ensures that strategic intent is clearly defined before the agent begins execution, and that long-term alignment is maintained throughout.

#### 2.1. Planning Mode: From Vision to Executable Subtasks

Planning Mode spans the entire journey from Roadmap to subtasks.json creation. This phase translates high-level strategic goals into granular, machine-executable work items while maintaining full traceability.

The process follows these steps:

1. **Roadmap Interpretation:** The high-level vision is decomposed into discrete User Stories—a critical step to "remember what we are building, for whom and why" that directly maps to the "Jobs to be Done" (JTBD) concept. Each Story receives a unique identifier.

2. **Gap Analysis:** The agent performs systematic comparison of the requirements in User Stories and supplementary technical documents against the current state of the codebase.

3. **Task Generation:** This analysis produces prioritized Tasks (`docs/planning/roadmap-<n>/tasks/*`), which marry the "why" from the Stories with the "how" from technical documentation. Each Task explicitly references its parent Story identifier.

4. **Subtask Decomposition:** Each Task is broken down into multiple granular Subtasks captured in `subtasks.json`. Each Subtask carries references to both its parent Task and grandparent Story, maintaining the traceability chain.

This comprehensive planning ensures the AI adheres to architectural standards while fulfilling user requirements, and that every Ralph Iteration has clear, atomic work to execute with full context of why that work matters.

#### 2.2. Building Mode: The Autonomous Coding Loop

In Building Mode, the agent operates autonomously, executing Subtasks generated in Planning Mode. Each Ralph Iteration is a discrete, self-contained session designed to make incremental progress while leaving the system in a clean, stable state. This incremental, one-Subtask-per-iteration approach directly solves the failure modes identified in Anthropic's research, such as agents attempting to "one-shot the app" or leaving the codebase in a broken, half-finished state.

A single Ralph Iteration follows these steps:

1. **Orient:** The agent starts with a completely fresh context, studying the current `subtasks.json`, the referenced User Story, and progress logs to "get its bearings."
2. **Select:** It identifies and selects a single, high-priority Subtask from subtasks.json to work on.
3. **Investigate:** The agent studies the relevant source code to confirm the Subtask is not already implemented, adhering to the critical "don't assume not implemented" guardrail.
4. **Implement:** The agent executes the Subtask, writing the necessary code changes.
5. **Validate:** The agent runs tests, linters, and build scripts. This "backpressure" provides immediate feedback, forcing the agent to self-correct until the code meets all predefined quality gates.
6. **Commit & Update:** Upon successful validation, the agent commits the changes with a descriptive message (referencing the Subtask, Task, and Story IDs), updates subtasks.json status, and leaves a "clean state" for the next Ralph Iteration.

When all Subtasks for a Task are complete, the Task is marked complete. When all Tasks for a Story are complete, the Story is marked complete.

### 3. Key Artifacts for State and Context Management

The framework's reliability and resilience are anchored by a set of file-based artifacts. These files provide persistent state, operational instructions, and an immutable source of truth, enabling the agent to function effectively and deterministically across countless memoryless Ralph Iterations.

#### 3.1. The Roadmap (`docs/planning/roadmap-<n>/`)

The high-level vision document that anchors all subsequent planning. It defines the strategic goals and major objectives that User Stories and Tasks must collectively achieve.

#### 3.2. User Stories (`docs/planning/roadmap-<n>/stories/*`)

These documents capture the user-centric "what" and "why" of the project. Each Story:
- Has a unique identifier (e.g., `STORY-001`)
- Defines outcomes and acceptance criteria
- Serves as the immutable source of truth for feature intent
- Is referenced by all child Tasks and grandchild Subtasks

By grounding every action in these specifications, the framework prevents the agent from inventing functionality or deviating from the project's core goals.

#### 3.3. Tasks (`docs/planning/roadmap-<n>/tasks/*`)

Technical implementation plans that bridge User Stories to code. Each Task:
- Has a unique identifier (e.g., `TASK-001`)
- References its parent Story (`storyRef: STORY-001`)
- Defines the specific technical approach
- Decomposes into multiple Subtasks
- Tracks completion status based on child Subtask completion

#### 3.4. Subtasks (`subtasks.json`)

The granular, machine-readable breakdown of Tasks into atomic execution units. Structure:

```json
{
  "subtasks": [
    {
      "id": "SUB-001",
      "taskRef": "TASK-001",
      "storyRef": "STORY-001",
      "description": "Create user authentication endpoint",
      "status": "pending",
      "acceptanceCriteria": ["Returns JWT on valid credentials", "Returns 401 on invalid"]
    }
  ]
}
```

This file is the agent's primary guide during Building Mode, defining exactly what work to do in each Ralph Iteration while preserving full traceability to the originating user need.

#### 3.5. The Operational Guide (`AGENTS.md`)

This file is the agent's concise "how-to" manual. As prescribed by the Ralph Playbook, it should contain only operational instructions, such as the specific commands to build, test, and lint the project. It must be kept lean and focused to avoid polluting the context of every loop with non-essential information like progress notes, which belong in the plan or logs.

#### 3.6. State Checkpoints (Git History & Progress Logs)

Git history and a dedicated progress file (such as the `claude-progress.txt` file used in Anthropic's research) provide a detailed, chronological record of work completed. Their primary function is to serve as the mechanism for a new agent session to quickly understand the project's current state and recent changes. This allows each fresh Ralph Iteration to orient itself without needing to re-analyze the entire codebase.

Commit messages should reference the traceability chain: `feat(SUB-003): implement password hashing [TASK-001][STORY-001]`

### 4. Calibration Mode: Governance and Self-Improvement

To transcend simple Subtask execution and achieve genuine autonomy, the system incorporates **Calibration Mode**—a set of higher-level feedback loops that run alongside the main workflow. These loops monitor for divergence from original intent, enforce technical standards, and enable the system to learn and improve its own performance over time.

#### 4.1. Monitoring for Intention Drift

**Intention Drift** is the divergence of the implementation from the original goals of the User Story or Roadmap. The traceability chain makes this detection possible—by following references from completed Subtasks back to their parent Story, a specialized subagent can compare the cumulative implementation against original acceptance criteria.

This audit runs periodically (perhaps every N Ralph Iterations or at Task completion boundaries), flagging any discrepancies for correction as new Subtasks or Tasks.

#### 4.2. Correcting for Technical Drift

**Technical Drift** is the deviation from established technical documentation, best practices, or architectural patterns. This is managed through an automated audit that compares the codebase against the technical specifications. The output of this audit is a list of deviations, which are then fed back into the system either as new Subtasks for immediate correction or as new Tasks to be planned in a future cycle—always maintaining proper references to affected Stories.

#### 4.3. Enabling Agent Self-Improvement

A truly autonomous system must be capable of self-improvement. This is achieved through a meta-analysis loop where the agent examines its own logs and conversation history. The objective is to identify patterns of struggle, inefficiency, or repeated errors. Based on these findings, the agent can generate suggestions for improving its own prompts, discovering better tools, or updating its operational knowledge base (e.g., refining commands in `AGENTS.md`).

### 5. Engineering Effective Backpressure

**Backpressure** is the most critical real-time mechanism for steering the agent and ensuring the quality of its output. It is a set of automated signals and gates that reject invalid work, thereby forcing the agent to iterate and self-correct until its output meets the required standards. It is the primary tool of the human "locomotive engineer."

#### 5.1. Programmatic Backpressure: Tests, Linters, and Builds

This is the foundational layer of backpressure. Unit tests, integration tests, type-checking, build scripts, and static analysis tools provide deterministic, binary (pass/fail) feedback. This forces the agent to produce code that is functionally correct, well-formed, and compliant with the project's basic coding standards before it can commit its work.

#### 5.2. Acceptance-Driven Backpressure

This advanced technique creates a direct, explicit link between the User Story and the validation process. During Planning Mode, specific test requirements are derived directly from the Story's acceptance criteria and flow down through Tasks to Subtasks. Each Subtask's `acceptanceCriteria` field defines what tests must pass. This ensures that the agent cannot mark a Subtask as complete until it has written and passed tests that prove it has met the specific, user-centric success criteria.

#### 5.3. Non-Deterministic Backpressure: The LLM-as-Judge

For subjective criteria that resist programmatic testing—such as user experience quality, aesthetic consistency, or the clarity of documentation—an innovative approach is to use a separate LLM call as a "judge." This judge provides a binary pass/fail review based on qualitative criteria defined in the User Story. While the judgment itself is non-deterministic, the iterative nature of the loop allows the agent to repeatedly refine its work based on the feedback until it achieves a "pass," ensuring that even subjective quality standards are met.

### 6. Conclusion: The New Role of the Software Engineer

This unified framework represents a fundamental paradigm shift in software creation, moving the developer from the role of a direct implementer to that of an architect and governor of an autonomous development system. The core of the work is no longer in the direct translation of ideas into code, but in the careful design of the system that performs that translation.

The engineer's primary responsibilities are now to:

- **Define clear specifications:** Craft precise User Stories and technical documents that serve as an unambiguous source of truth, with proper identifiers enabling full traceability.
- **Engineer a robust environment:** Construct a system of effective backpressure using tests, static analysis, and LLM-based judges to guide the agent toward quality outcomes.
- **Observe and tune the system:** Monitor the agent's performance through Calibration Mode, identify failure patterns, and refine the prompts, tools, and feedback loops to continuously improve its efficiency and reliability.

By automating the development loop, we empower our teams to focus on higher-level strategic and architectural challenges. This new role represents a necessary evolution from _software development_ to _software engineering_, a distinction Geoffrey Huntley highlights as critical for harnessing the potential of autonomous systems to fundamentally alter the economics and velocity of our industry.