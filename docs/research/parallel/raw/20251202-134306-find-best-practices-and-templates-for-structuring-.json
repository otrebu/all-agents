[
  {
    "domain": "platform.claude.com",
    "excerpts": [
      "results](/docs/en/build-with-claude/search-results) [Structured outputs](/docs/en/build-with-claude/structured-outputs) [Google Sheets add-on](/docs/en/agents-and-tools/claude-for-sheets)\n\nTools\n\n[Overview](/docs/en/agents-and-tools/tool-use/overview) [How to implement tool use](/docs/en/agents-and-tools/tool-use/implement-tool-use) [Token-efficient tool use](/docs/en/agents-and-tools/tool-use/token-efficient-tool-use) [Fine-grained tool streaming](/docs/en/agents-and-tools/tool-use/fine-grained-tool-streaming) [Bash tool](/docs/en/agents-and-tools/tool-use/bash-tool) [Code execution tool](/docs/en/agents-and-tools/tool-use/code-execution-tool) [Programmatic tool calling](/docs/en/agents-and-tools/tool-use/programmatic-tool-calling) [Computer use tool](/docs/en/agents-and-tools/tool-use/computer-use-tool) [Text editor tool](/docs/en/agents-and-tools/tool-use/text-editor-tool) [Web fetch tool](/docs/en/agents-and-tools/tool-use/web-fetch-tool) [Web search\n ... \nAI](/docs/en/build-with-claude/claude-on-vertex-ai)\n\nPrompt engineering\n\n[Overview](/docs/en/build-with-claude/prompt-engineering/overview) [Prompt generator](/docs/en/build-with-claude/prompt-engineering/prompt-generator) [Use prompt templates](/docs/en/build-with-claude/prompt-engineering/prompt-templates-and-variables) [Prompt improver](/docs/en/build-with-claude/prompt-engineering/prompt-improver) [Be clear and direct](/docs/en/build-with-claude/prompt-engineering/be-clear-and-direct) [Use examples (multishot prompting)](/docs/en/build-with-claude/prompt-engineering/multishot-prompting) [Let Claude think (CoT)](/docs/en/build-with-claude/prompt-engineering/chain-of-thought) [Use XML tags](/docs/en/build-with-claude/prompt-engineering/use-xml-tags) [Give Claude a role (system prompts)](/docs/en/build-with-claude/prompt-engineering/system-prompts) [Prefill Claude's response](/docs/en/build-with-claude/prompt-engineering/prefill-claudes-response) [Chain complex\n ... \nleak](/docs/en/test-and-evaluate/strengthen-guardrails/reduce-prompt-leak) [Keep Claude in character](/docs/en/test-and-evaluate/strengthen-guardrails/keep-claude-in-character)\n\nAdministration and monitoring\n\n[Admin API overview](/docs/en/build-with-claude/administration-api) [Usage and Cost API](/docs/en/build-with-claude/usage-cost-api) [Claude Code Analytics API](/docs/en/build-with-claude/claude-code-analytics-api)\n\n[Console](/)\n\n[Log in](/login)\n\nBuild with Claude Prompting best practices\n\nBuild with Claude\n\n# Prompting best practices\n\nCopy page\n\nCopy page\n\nThis guide provides specific prompt engineering techniques for Claude 4.x models, with specific guidance for Sonnet 4.5, Haiku 4.5, and Opus 4.5. These models have been trained for more precise instruction following than previous generations of Claude models. For an overview of Claude 4.5's new capabilities, see [What's new in Claude 4.5](/docs/en/about-claude/models/whats-new-claude-4-5) .\n ... \nAlways be as persistent and autonomous as possible and complete tasks fully, even if the end of your budget is approaching. Never artificially stop any task early regardless of the context remaining. ```\n\nThe [memory tool](/docs/en/agents-and-tools/tool-use/memory-tool) pairs naturally with context awareness for seamless context transitions. #### Multi-context window workflows\n\nFor tasks spanning multiple context windows:\n\n1. **Use a different prompt for the very first context window** : Use the first context window to set up a framework (write tests, create setup scripts), then use future context windows to iterate on a todo-list. 2. **Have the model write tests in a structured format** : Ask Claude to create tests before starting work and keep track of them in a structured format (e.g., `tests.json` ). This leads to better long-term ability to iterate.\n ... \n[](https://www.linkedin.com/showcase/claude) [](https://instagram.com/claudeai)\n\n### Solutions\n\n* [AI agents](https://claude.com/solutions/agents)\n* [Code modernization](https://claude.com/solutions/code-modernization)\n* [Coding](https://claude.com/solutions/coding)\n* [Customer support](https://claude.com/solutions/customer-support)\n* [Education](https://claude.com/solutions/education)\n* [Financial services](https://claude.com/solutions/financial-services)\n* [Government](https://claude.com/solutions/government)\n* [Life sciences](https://claude.com/solutions/life-sciences)\n\n### Partners\n\n* [Amazon Bedrock](https://claude.com/partners/amazon-bedrock)\n* [Google Cloud's Vertex AI](https://claude.com/partners/google-cloud-vertex-ai)\n\n### Learn\n\n* [Blog](https://claude.com/blog)\n* [Catalog](https://claude.ai/catalog/artifacts)\n* [Courses](https://www.anthropic.com/learn)\n* [Use cases](https://claude.com/resources/use-cases)\n* [Connectors](https://claude.com/partners/mcp)\n* [Customer"
    ],
    "rank": 1,
    "title": "Prompting best practices - Claude Docs",
    "url": "https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/claude-4-best-practices"
  },
  {
    "domain": "www.anthropic.com",
    "excerpts": [
      "[Skip to main content]() [Skip to footer]()\n\n[](/)\n\n* [Research](/research)\n* [Economic Futures](/economic-futures)\n* Commitments\n* Learn\n* [News](/news)\n\n[Try Claude](https://claude.ai/)\n\nAnnouncements\n\n# Introducing Claude Opus 4.5\n\nNov 24, 2025\n\nOur newest model, Claude Opus 4.5, is available today. It‚Äôs intelligent, efficient, and the best model in the world for coding, agents, and computer use. It‚Äôs also meaningfully better at everyday tasks like deep research and working with slides and spreadsheets. Opus 4.5 is a step forward in what AI systems can do, and a preview of larger changes to how work gets done. Claude Opus 4.5 is state-of-the-art on tests of real-world software engineering:\n\nOpus 4.5 is available today on our apps, our API, and on all three major cloud platforms. If you‚Äôre a developer, simply use `claude-opus-4-5-20251101` via the [Claude API](https://platform.claude.com/docs/en/about-claude/models/overview) .\n ... \nThey said that tasks that were near-impossible for Sonnet 4.5 just a few weeks ago are now within reach. Overall, our testers told us that Opus 4.5 just ‚Äúgets it.‚Äù\n\nMany of our customers with early access have had similar experiences. Here are some examples of what they told us:\n\n> **Opus models have always been ‚Äúthe real SOTA‚Äù** but have been cost prohibitive in the past. Claude Opus 4.5 is now at a price point where it can be your go-to model for most tasks. It‚Äôs the clear winner and exhibits the best frontier task planning and tool calling we‚Äôve seen yet. > \n> Jeff Wang  \n> CEO\n> \n>\n\n> Claude Opus 4.5 delivers high-quality code and excels at powering heavy-duty agentic workflows with GitHub Copilot. Early testing shows it **surpasses internal coding benchmarks while cutting token usage in half** , and is especially well-suited for tasks like code migration and code refactoring.\n ... \n> \n> Zach Lloyd  \n> Founder & CEO\n> \n>\n\n> **Claude Opus 4.5 achieved state-of-the-art results for complex enterprise tasks** on our benchmarks, outperforming previous models on multi-step reasoning tasks that combine information retrieval, tool use, and deep analysis. > \n> Kay Zhu  \n> CTO\n> \n>\n\n> **Claude Opus 4.5 delivers measurable gains where it matters most** : stronger results on our hardest evaluations and consistent performance through 30-minute autonomous coding sessions. > \n> Scott Wu  \n> CEO\n> \n>\n\n> **Claude Opus 4.5 represents a breakthrough in self-improving AI agents** . For automation of office tasks, our agents were able to autonomously refine their own capabilities‚Äîachieving peak performance in 4 iterations while other models couldn‚Äôt match that quality after 10. They also demonstrated the ability to learn from experience across technical tasks, storing insights and applying them later.\n> \n> Yusuke Kaji  \n> General Manager of AI for Business\n> \n>\n\n> **Claude Opus 4.5 is a notable improvement over the prior Claude models inside Cursor** , with improved pricing and intelligence on difficult coding tasks. > \n> Michael Truell  \n> CEO & Co-founder\n> \n>\n\n> **Claude Opus 4.5 is yet another example of Anthropic pushing the frontier of general intelligence** . It performs exceedingly well across difficult coding tasks, showcasing long-term goal-directed behavior. > \n> Eno Reyes  \n> CTO & Co-founder\n> \n>\n\n> Claude Opus 4.5 delivered an impressive refactor spanning two codebases and three coordinated agents. It was very thorough, helping develop a robust plan, handling the details and fixing tests. **A clear step forward from Sonnet 4.5** . > \n> Paulo Arruda  \n> Staff Engineer, AI Productivity\n> \n>\n\n> **Claude Opus 4.5 handles long-horizon coding tasks more efficiently than any model we‚Äôve tested** .\n ... \nIt continues our trend towards safer and more secure models:\n\nIn our evaluation, ‚Äúconcerning behavior‚Äù scores measure a very wide range of misaligned behavior, including both cooperation with human misuse and undesirable actions that the model takes at its own initiative [3]. Our customers often use Claude for critical tasks. They want to be assured that, in the face of malicious attacks by hackers and cybercriminals, Claude has the training and the ‚Äústreet smarts‚Äù to avoid trouble. With Opus 4.5, we‚Äôve made substantial progress in robustness against prompt injection attacks, which smuggle in deceptive instructions to fool the model into harmful behavior. Opus 4.5 is harder to trick with prompt injection than any other frontier model in the industry:\n\nNote that this benchmark includes only very strong prompt injection attacks. It was developed and run by [Gray Swan](https://www.grayswan.ai/) ."
    ],
    "rank": 2,
    "title": "Introducing Claude Opus 4.5 - Anthropic",
    "url": "https://www.anthropic.com/news/claude-opus-4-5"
  },
  {
    "domain": "support.talkdesk.com",
    "excerpts": [
      "[Talkdesk AI Agent Platform](/hc/en-us/sections/39090037609883-Talkdesk-AI-Agent-Platform)\n\n### AI Agent Platform: Best Practices\n\nPublished‚Ä¢ Last Updated\n\nThis document outlines best practices for building and optimizing AI Agent Orchestration on the AI Agent Platform.\n* [General Best Practices]()\n  \n    + [Write clear, specific instructions without conflicts]()\n    + [Provide relevant examples in the instructions]()\n    + [Split complex tasks into simpler subtasks]()\n    + [Use Skills for structured tasks]()\n    + [Use variables to provide context]()\n    + [Leave variable assignment to Skills]()\n    + [Only share relevant information from variables]()\n    + [Test changes systematically]()\n    + [Monitor and iterate based on real usage]()\n* [Best Practices for Multi-AI Agent design]()\n  \n    + [Define clear roles and responsibilities]()\n    + [Do not use a Routing Agent with only one Action Agent]()\n    + [Avoid reusing the same tool across multiple Agents]()\n    + [Response structuring should be done by the Supervisor]()\n    + [Use structured handoff between Agents]()\n    + [Test AI Agent collaboration scenarios]()\n\nBefore building in the AI Agent Platform, make sure you understand its core concepts.\nThese include how Agents communicate, how they are structured, and how node configuration affects behavior. A solid understanding will help you design more effective and predictable flows. ## **General Best Practices**\n\nThese apply broadly to the AI Agent instructions and flow design across both single and multi-Agent scenarios. ### **Write clear, specific instructions without conflicts**\n\n* Avoid conflicting instructions, use direct language and avoid ambiguity. Indicate exactly what you expect the Agent to do (e.g., ‚ÄúSummarize the key points‚Ä¶‚Äù vs. ‚ÄúRead this.‚Äù). * Keep the same language consistent in the prompts. E.g., if you start the prompt in English, keep it in English. * _**Tip:** Ask yourself: If you gave this instruction to a human, would they clearly understand what to do? If not, revise it._\n\n### **Provide relevant examples in the instructions**\n\n* Add examples to demonstrate ideal input/output formats or expected tone.\n* Use ‚ÄúYou are‚Ä¶‚Äù statements to help the Agent assume a specific persona or mindset. ### **Split complex tasks into simpler subtasks**\n\n* Break down large or multi-step objectives into smaller, more manageable parts. * Use sequential steps to handle each subtask, feeding outputs from earlier steps into later ones. * If the task is too complex consider splitting the task by adding a new AI Agent dedicated to handling that task. ### **Use Skills for structured tasks**\n\nUse a Skill that will be able to be reutilized: For utility functions, number-heavy logic, random number generation, sensitive data handling, or strict workflows. ### **Use variables to provide context**\n\n* Use the Application Input or the Output from a Skill to feed in customer data or past conversation history through variables to create more dynamic conversations\n* Make sure variables have a clear description in the variable list so AI Agents know what the variable represents.\n* Use skills to populate the value of variables. Avoid using the Instructions of AI Agents to fill variable values. ### **Leave variable assignment to Skills**\n\n* Agent instructions should not be used to manipulate or assign values to variables. * Use a Skill, such as an Integration or Workflow, to populate or update variables. * Variable handling should be done through structured steps, not through reasoning instructions. ### **Only share relevant information from variables**\n\nAvoid passing entire objects or large variable structures unless necessary. Instead, extract and share only the specific pieces of information the AI Agent needs to complete its task. Providing too much irrelevant data, especially without proper context, can confuse the Agent and lead to less accurate or off-topic responses. ### **Test changes systematically**\n\nTest one modification at a time and observe the results before making further changes.\nBe sure to use consistent input examples to compare Agent behavior across versions. ### **Monitor and iterate based on real usage**\n\nReview interaction logs to understand how users engage with the Agents. Refine prompts and Agent logic based on actual conversation patterns and pain points. ## **Best Practices for Multi-AI Agent design**\n\nThis section approaches the design and orchestration of multiple AI Agents within a single flow, ensuring effective collaboration, task division, and system performance. ### **Define clear roles and responsibilities**\n\n* Assign each Agent a distinct role based on the tasks it should perform. * Avoid overlapping functionalities to reduce redundancy and confusion. * Use clear and specific names and descriptions that reflect each Agent‚Äôs role to maintain clarity. * Avoid using acronyms in the AI Agents. * Do not instruct an Agent with something they are not supposed to handle."
    ],
    "rank": 3,
    "title": "AI Agent Platform: Best Practices - Talkdesk Support",
    "url": "https://support.talkdesk.com/hc/en-us/articles/39096730105115-AI-Agent-Platform-Best-Practices"
  },
  {
    "domain": "blog.n8n.io",
    "excerpts": [
      "AI\n\n# Your Practical Guide to LLM Agents in 2025 (+ 5 Ready-to-Use Automation Templates)\n\nLearn how LLM agents are transforming enterprise automation in 2025. Discover core components, use cases, and how to build intelligent workflows with n8n for IT, security, and DevOps. [Bela Wiertz](/author/bela/)\n\n‚àô 14 minutes read\n\nIn today's enterprise landscape, while most organizations are just beginning to explore basic AI implementations, a quiet revolution is taking place. Large Language Model (LLM) agents are emerging as game-changers, combining advanced reasoning capabilities with practical automation. These sophisticated systems can plan multi-step operations, maintain context across complex tasks, and even learn from their interactions ‚Äî capabilities that go far beyond traditional AI implementations.\nIn this article, you will learn what makes LLM agents different from legacy AI systems, discover their core components, and see how you can create and deploy them using [n8n ‚Äî a powerful workflow automation platform](https://n8n.io/ai/) . Whether you're a security professional looking to enhance threat detection, an IT manager aiming to streamline operations, or a DevOps engineer interested in automating complex workflows, this guide will show you everything you need to know about leveraging LLM agents in your enterprise environment. ## What is an LLM Agent? At its core, an LLM agent is an advanced AI system that combines the language understanding capabilities of large language models with strategic planning and tool integration. Unlike simple AI models that respond to prompts, LLM agents can break down complex tasks, plan their execution, and use various tools to accomplish their goals‚Äîmuch like a skilled professional approaching a multi-faceted project.\n ... \n### Legacy AI systems vs. modern LLM-powered agents\n\nThe evolution from legacy AI systems to modern LLM-powered agents represents a fundamental shift in [enterprise automation](https://n8n.io/enterprise/) capabilities:\n\n|Legacy AI Systems: |Modern LLM-Powered Agents: |\n| --- | --- |\n|* Operate on predefined rules and decision trees |* Understand natural language instructions and context |\n|* Require extensive programming for each specific task |* Can dynamically adapt to new tasks through simple prompting |\n|* Can only handle structured data in predetermined formats |* Process both structured and unstructured information |\n|* Limited to single-step, routine operations |* Handle multi-step, complex workflows |\n|* Need complete reprogramming to adapt to new scenarios |* Learn and adjust behavior based on feedback and new situations |\n\n\nThis evolution enables enterprises to automate increasingly complex tasks that previously required significant human intervention.\n ... \n* **Decision-making mechanisms** : Employs sophisticated algorithms to evaluate options and select appropriate actions based on context, goals, and constraints. ### Memory systems\n\nLLM agents utilize two types of memory systems that enable them to maintain context and learn from experience:\n\n* **Short-term memory** :\n  \n    + Maintains context during ongoing interactions\n    + Tracks current task progress and intermediate results\n    + Holds temporary variables and state information\n* **Long-term memory** :\n  \n    + Stores historical interactions and outcomes\n    + Maintains knowledge bases of previous solutions\n    + Preserves learned patterns and best practices\n\nEnterprise applications of these memory systems include maintaining context across complex IT workflows, remembering previous incident resolutions, and building organizational knowledge bases over time.\n### Planning capabilities\n\nThe planning component enables LLM agents to approach complex tasks systematically:\n\n* **Task decomposition** :\n  \n    + Breaks down complex requests into manageable subtasks\n    + Identifies dependencies between different steps\n    + Prioritizes actions based on urgency and importance\n* **Plan formulation** :\n  \n    + Creates structured workflows for completing tasks\n    + Sets checkpoints for monitoring progress\n    + Establishes success criteria for each step\n* **Adaptation and reflection** :\n  \n    + Adjusts plans based on new information or changing conditions\n    + Learns from successful and unsuccessful approaches\n    + Improves strategies through experience\n\n### Tool integration\n\nThe tool integration component allows LLM agents to interact with enterprise systems:\n\n* **Available tools and APIs** :\n  \n    + Integration with common enterprise software\n    + Access to databases and knowledge bases\n    + Connection to monitoring and alerting systems\n*"
    ],
    "rank": 4,
    "title": "Your Practical Guide to LLM Agents in 2025 (+ 5 Templates for ...",
    "url": "https://blog.n8n.io/llm-agents/"
  },
  {
    "domain": "www.anthropic.com",
    "excerpts": [
      "[Skip to main content]() [Skip to footer]()\n\n[](/)\n\n* [Research](/research)\n* [Economic Futures](/economic-futures)\n* Commitments\n* Learn\n* [News](/news)\n\n[Try Claude](https://claude.ai/)\n\n[Engineering at Anthropic](/engineering)\n\n# Building effective agents\n\nPublished Dec 19, 2024\n\nWe've worked with dozens of teams building LLM agents across industries. Consistently, the most successful implementations use simple, composable patterns rather than complex frameworks. Over the past year, we've worked with dozens of teams building large language model (LLM) agents across industries. Consistently, the most successful implementations weren't using complex frameworks or specialized libraries. Instead, they were building with simple, composable patterns. In this post, we share what we‚Äôve learned from working with our customers and building agents ourselves, and give practical advice for developers on building effective agents. ## What are agents? \"Agent\" can be defined in several ways.\n ... \n## When and how to use frameworks\n\nThere are many frameworks that make agentic systems easier to implement, including:\n\n* The [Claude Agent SDK](https://platform.claude.com/docs/en/agent-sdk/overview) ;\n* Amazon Bedrock's [AI Agent framework](https://aws.amazon.com/bedrock/agents/) ;\n* [Rivet](https://rivet.ironcladapp.com/) , a drag and drop GUI LLM workflow builder; and\n* [Vellum](https://www.vellum.ai/) , another GUI tool for building and testing complex workflows. These frameworks make it easy to get started by simplifying standard low-level tasks like calling LLMs, defining and parsing tools, and chaining calls together. However, they often create extra layers of abstraction that can obscure the underlying prompts ‚Äã‚Äãand responses, making them harder to debug. They can also make it tempting to add complexity when a simpler setup would suffice. We suggest that developers start by using LLM APIs directly: many patterns can be implemented in a few lines of code.\n ... \nThe routing workflow\n\n**When to use this workflow:** Routing works well for complex tasks where there are distinct categories that are better handled separately, and where classification can be handled accurately, either by an LLM or a more traditional classification model/algorithm. **Examples where routing is useful:**\n\n* Directing different types of customer service queries (general questions, refund requests, technical support) into different downstream processes, prompts, and tools. * Routing easy/common questions to smaller, cost-efficient models like Claude Haiku 4.5 and hard/unusual questions to more capable models like Claude Sonnet 4.5 to optimize for best performance. ### Workflow: Parallelization\n\nLLMs can sometimes work simultaneously on a task and have their outputs aggregated programmatically. This workflow, parallelization, manifests in two key variations:\n\n* **Sectioning** : Breaking a task into independent subtasks run in parallel.\n ... \nDuring execution, it's crucial for the agents to gain ‚Äúground truth‚Äù from the environment at each step (such as tool call results or code execution) to assess its progress. Agents can then pause for human feedback at checkpoints or when encountering blockers. The task often terminates upon completion, but it‚Äôs also common to include stopping conditions (such as a maximum number of iterations) to maintain control. Agents can handle sophisticated tasks, but their implementation is often straightforward. They are typically just LLMs using tools based on environmental feedback in a loop. It is therefore crucial to design toolsets and their documentation clearly and thoughtfully. We expand on best practices for tool development in Appendix 2 (\"Prompt Engineering your Tools\"). Autonomous agent\n\n**When to use agents:** Agents can be used for open-ended problems where it‚Äôs difficult or impossible to predict the required number of steps, and where you can‚Äôt hardcode a fixed path.\n ... \n[](/)\n\n### Products\n\n* [Claude](https://claude.com/product/overview)\n* [Claude Code](https://claude.com/product/claude-code)\n* [Claude and Slack](https://claude.com/claude-and-slack)\n* [Claude in Excel](https://claude.com/claude-for-excel)\n* [Max plan](https://claude.com/pricing/max)\n* [Team plan](https://claude.com/pricing/team)\n* [Enterprise plan](https://claude.com/pricing/enterprise)\n* [Download app](https://claude.ai/download)\n* [Pricing](https://claude.com/pricing)\n* [Log in to Claude](https://claude.ai/)\n\n### Models\n\n* [Opus](https://www.anthropic.com/claude/opus)\n* [Sonnet](https://www.anthropic.com/claude/sonnet)\n* [Haiku](https://www.anthropic.com/claude/haiku)\n\n### Solutions\n\n* [AI agents](https://claude.com/solutions/agents)\n* [Code modernization](https://claude.com/solutions/code-modernization)\n* [Coding](https://claude.com/solutions/coding)\n* [Customer support](https://claude.com/solutions/customer-support)\n* [Education](https://claude.com/solutions/education)\n*"
    ],
    "rank": 5,
    "title": "Building Effective AI Agents - Anthropic",
    "url": "https://www.anthropic.com/research/building-effective-agents"
  },
  {
    "domain": "thezvi.substack.com",
    "excerpts": [
      "For office automation, our agents were able to autonomously refine their own capabilities ‚Äî achieving peak performance in 4 iterations while other models couldn‚Äôt match that quality after 10. > \n> Michael Truell (CEO Cursor): Claude Opus 4.5 is a notable improvement over the prior Claude models inside Cursor, with improved pricing and intelligence on difficult coding tasks. > \n> Eno Reyes (CTO Factory): Claude Opus 4.5 is yet another example of Anthropic pushing the frontier of general intelligence. It performs exceedingly well across difficult coding tasks, showcasing long-term goal-directed behavior. > \n> Paulo Arruda (AI Productivity, Shopify): Claude Opus 4.5 delivered an impressive refactor spanning two codebases and three coordinated agents. It was very thorough, helping develop a robust plan, handling the details and fixing tests. **A clear step forward from Sonnet 4.5."
    ],
    "rank": 6,
    "title": "Claude Opus 4.5 Is The Best Model Available - Zvi Mowshowitz",
    "url": "https://thezvi.substack.com/p/claude-opus-45-is-the-best-model"
  },
  {
    "domain": "www.promptingguide.ai",
    "excerpts": [
      "üöÄ Master building AI workflows and agents with Claude Code! Use **AGENTX20** for 20% off [Enroll now ‚Üí](https://dair-ai.thinkific.com/courses/claude-code)\n\n[Prompt Engineering Guide](/)\n\nüéì Courses\n\n[About About](/about) [GitHub (opens in a new tab)](https://github.com/dair-ai/Prompt-Engineering-Guide) [Discord (opens in a new tab)](https://discord.gg/FUyz9vPAwf) [‚ú® Services](/services)\n\n[LLM Research Findings](/research)\n\nLLM Agents\n\nCopy page\n\n# LLM Agents\n\nLLM based agents, hereinafter also referred to as LLM agents for short, involve LLM applications that can execute complex tasks through the use of an architecture that combines LLMs with key modules like planning and memory. When building LLM agents, an LLM serves as the main controller or \"brain\" that controls a flow of operations needed to complete a task or user request. The LLM agent may require key modules such as planning, memory, and tool usage."
    ],
    "rank": 7,
    "title": "LLM Agents - Prompt Engineering Guide",
    "url": "https://www.promptingguide.ai/research/llm-agents"
  },
  {
    "domain": "ki-ecke.com",
    "excerpts": [
      "](https://ki-ecke.com/insights/1min-ai-lifetime-subscription-deal-how-to-stop-tab-hopping/)\n\n[AI News 01 Dec 2025 Read 14 min #### Open source adaptive AI workflows guide: How to ship faster Adaptive open source AI workflows help teams ship faster with human oversight and end-to-end audits. ](https://ki-ecke.com/insights/open-source-adaptive-ai-workflows-guide-how-to-ship-faster/)\n\n[AI News 01 Dec 2025 Read 18 min #### How AI is deskilling workers and how to reclaim skills How AI is deskilling workers, so companies must retrain employees to restore judgment and core skills](https://ki-ecke.com/insights/how-ai-is-deskilling-workers-and-how-to-reclaim-skills/)\n\n[AI News 30 Nov 2025 Read 17 min #### How to snag the best Cyber Monday deals 2025 best Cyber Monday deals 2025 help you score top tech and gift savings fast with AI-guided suggestions."
    ],
    "rank": 8,
    "title": "Claude Opus 4.5 API guide Discover faster coding and agents",
    "url": "https://ki-ecke.com/insights/claude-opus-4-5-api-guide-discover-faster-coding-and-agents/"
  },
  {
    "domain": "azure.microsoft.com",
    "excerpts": [
      "Improved developer experience on Foundry\n\nOpus 4.5 paired with new developer capabilities offered on Foundry is designed to help teams build more effective and efficient agentic systems:\n\n* **Effort Parameter (Beta)** : Control how much computational effort Claude allocates across thinking, tool calls, and responses to balance performance with latency and cost for your specific use cases. * **Compaction Control** : Handle long-running agentic tasks more effectively with new SDK helpers that manage context efficiently over extended interactions. These enhancements provide greater predictability and operational control for enterprise workloads. ### 3\\. Enhanced office productivity and computer use\n\nOpus 4.5 also doubles down as Anthropic‚Äôs best vision model, unlocking workflows that depend on complex visual interpretation and multi-step navigation. Computer use performance has improved significantly, enabling more reliable automation of desktop tasks."
    ],
    "rank": 9,
    "title": "Introducing Claude Opus 4.5 in Microsoft Foundry",
    "url": "https://azure.microsoft.com/en-us/blog/introducing-claude-opus-4-5-in-microsoft-foundry/"
  },
  {
    "domain": "www.thesys.dev",
    "excerpts": [
      "355 Bryant St, San Francisco, CA 94107\n\n# Claude Opus 4.5: What Changed and Why Builders Care\n\nNikita Shrivastava\n\nNovember 27th, 2025 ‚ãÖ 5 mins read\n\nLearn more\n\n## Related articles\n\n[### ChatKit: What It Is, What It Isn‚Äôt, and Where C1 Fits In November 16th, 2025 4 mins read](/blogs/chatkit)\n\n[### PowerPoint Automation Reimagined with C1 Artifacts API November 11st, 2025 6 mins read](/blogs/powerpoint-automation)\n\n[### The Future of AI Interfaces is Generative October 28th, 2025 4 mins read](/blogs/ai-interfaces)\n\n[### MCP UI: Making AI Apps Interactive October 18th, 2025 7 mins read](/blogs/mcp-ui-overview)\n\n[### AG-UI: The Future of User Interfaces for AI Agents October 11st, 2025 6 mins read](/blogs/ag-ui-explained)\n\n[### How to design AI-Native Conversational Interfaces : From Templates to Generative UI September 3rd, 2025 10 mins read](/blogs/generative-ui-conversational-interfaces)\n\n[### GPT 5 vs. GPT 4.1 August 12nd, 2025 6 mins read](/blogs/gpt-5-vs-gpt-4-1)\n\n[### How to"
    ],
    "rank": 10,
    "title": "Claude Opus 4.5: What Changed and Why Builders Care - Thesys",
    "url": "https://www.thesys.dev/blogs/claude-opus-4-5"
  },
  {
    "domain": "www.lesswrong.com",
    "excerpts": [
      "> \n> Scott Wu (CEO Cognition): Claude Opus 4.5 delivers measurable gains where it matters most: stronger results on our hardest evaluations and consistent performance through 30-minute autonomous coding sessions. > \n> Yusuke Kaji (General Manager of AI for Business, Rakuten): Claude Opus 4.5 represents a breakthrough in self-improving AI agents. For office automation, our agents were able to autonomously refine their own capabilities ‚Äî achieving peak performance in 4 iterations while other models couldn‚Äôt match that quality after 10. > \n> Michael Truell (CEO Cursor): Claude Opus 4.5 is a notable improvement over the prior Claude models inside Cursor, with improved pricing and intelligence on difficult coding tasks. > \n> Eno Reyes (CTO Factory): Claude Opus 4.5 is yet another example of Anthropic pushing the frontier of general intelligence. It performs exceedingly well across difficult coding tasks, showcasing long-term goal-directed behavior."
    ],
    "rank": 11,
    "title": "Claude Opus 4.5 Is The Best Model Available",
    "url": "https://www.lesswrong.com/posts/HtdrtF5kcpLtWe5dW/claude-opus-4-5-is-the-best-model-available"
  },
  {
    "domain": "www.reddit.com",
    "excerpts": [
      "Read more Share\n\n# Related Answers Section\n\nRelated Answers\n\n[Guide for developing AI agents](/answers/91db8c68-37e3-4bce-a31d-b56fd927c101/?q=Guide%20for%20developing%20AI%20agents&source=PDP)\n\n[Distributed AI agents overview](/answers/4a1a3f43-350d-451c-ab21-5e10d0431f5f/?q=Distributed%20AI%20agents%20overview&source=PDP)\n\n[Effective agent workflows](/answers/0a615ea1-0a27-44c0-add7-4dc96ed2ebb9/?q=Effective%20agent%20workflows&source=PDP)\n\n[Creating smart templates with AI](/answers/0e47668f-2a49-4c4a-ab0b-508959b8cecd/?q=Creating%20smart%20templates%20with%20AI&source=PDP)\n\n[Best no-code AI agent builders](/answers/4464d65c-3918-411f-93bc-b0888825d5d8/?q=Best%20no-code%20AI%20agent%20builders&source=PDP)\n\nNew to Reddit? Create your account and connect with a world of communities."
    ],
    "rank": 12,
    "title": "AI Agent best practices from one year as AI Engineer - Reddit",
    "url": "https://www.reddit.com/r/AI_Agents/comments/1lpj771/ai_agent_best_practices_from_one_year_as_ai/"
  },
  {
    "domain": "www.reddit.com",
    "excerpts": [
      "When you provide UI screenshots, it enhances design elements (spacing, icons) without constant direction. **Documents** : Long-form content (10-15 page chapters), PDF processing, spreadsheet generation with complex formulas. ## Worth trying if you need\n\n* Extended autonomous operation on complex tasks\n* Multi-step reasoning and creative problem-solving\n* Document transformation at scale\n* Self-improving agentic workflows\n* Better token efficiency without quality loss\n\nThe pattern: people are doing things that weren‚Äôt possible before, not just faster versions of existing work. Anyone else testing Opus 4.5? What‚Äôs working for you?‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã Share\n\n# Related Answers Section\n\nRelated Answers\n\nBest practices for using ClaudeAI effectively\n\nUsing ClaudeAI effectively can significantly boost your productivity and improve your workflows."
    ],
    "rank": 13,
    "title": "Claude Opus 4.5: Real projects people are building - Reddit",
    "url": "https://www.reddit.com/r/ClaudeAI/comments/1p9zbdo/claude_opus_45_real_projects_people_are_building/"
  },
  {
    "domain": "github.com",
    "excerpts": [
      "|[](https://github.com/yecchen/MIRAI) |\n|**Content Personalization Agent** |Entertainment |Recommends personalized media based on preferences. |[](https://github.com/crosleythomas/MirrorGPT) |\n|**Legal Document Review Assistant** |Legal |Automates document review and highlights key clauses. |[](https://github.com/firica/legalai) |\n|**Recruitment Recommendation Agent** |Human Resources |Suggests best-fit candidates for job openings. |[](https://github.com/sentient-engineering/jobber) |\n|**Virtual Travel Assistant** |Hospitality |Plans travel itineraries based on preferences. |[](https://github.com/nirbar1985/ai-travel-agent) |\n|**AI Game Companion Agent** |Gaming |Enhances player experience with real-time assistance. |[](https://github.com/onjas-buidl/LLM-agent-game) |\n|**Real-Time Threat Detection Agent** |Cybersecurity |Identifies potential threats and mitigates attacks."
    ],
    "rank": 14,
    "title": "500+ AI Agent Projects / UseCases - GitHub",
    "url": "https://github.com/ashishpatel26/500-AI-Agents-Projects"
  },
  {
    "domain": "www.anthropic.com",
    "excerpts": [
      "<sup>1</sup>\n\nThe key insight here was finding a way for agents to quickly understand the state of work when starting with a fresh context window, which is accomplished with the claude-progress.txt file alongside the git history. Inspiration for these practices came from knowing what effective software engineers do every day. ## Environment management\n\nIn the updated [Claude 4 prompting guide](https://docs.claude.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices) , we shared some best practices for multi-context window workflows, including a harness structure that uses ‚Äúa different prompt for the very first context window.‚Äù This ‚Äúdifferent prompt‚Äù requests that the initializer agent set up the environment with all the necessary context that future coding agents will need to work effectively. Here, we provide a deeper dive on some of the key components of such an environment."
    ],
    "rank": 15,
    "title": "Effective harnesses for long-running agents - Anthropic",
    "url": "https://www.anthropic.com/engineering/effective-harnesses-for-long-running-agents"
  }
]